---
layout: reveal
title: ImageNet and ReNet Papers
pres: true
---

A presentation on two papers, Krizhevsky, et al., “ImageNet Classification with
Deep Convolutional Neural Networks” and Visin et al., “ReNet: A Recurrent
Neural Network Based Alternative to Convolutional Networks”.

Images are taken from these papers, unless otherwise noted.

When I wrote these slides, I didn't have reveal.js working. It's now working,
but I'm not going back to reformat everything, so my apologies for the poor
appearance.

<br>

---

<br>

Deep CNNs for ImageNet
======================

* ImageNet Large Scale Visual Recognition Challenge contests, 2010 and 2012 (winner)
* Large, deep convolutional neural network
  * 650,000 neurons
  * 60 million parameters
  * Five convolutional layers (some with max pooling)
  * Three fully-connected layers, final 1000-way softmax
* Training accelerations
  * Non-saturating neurons
  * GPUs
* Reduced overfitting with dropout

<br>

---

<br>

The Data: ImageNet Large Scale Visual Recognition Challenge (ILSVRC)
====================================================================

* Labeled by humans (Mechanical Turk)
* Full data set: 15 million images, 22,000 categories
* Contest data set
  * 1000 categories, ~1000 images per category
  * 1.2 million training images, 50k validation images, 150k test images
* Various resolutions, downsampled to 256x256 for the following

<br>

---

<br>

The Architecture
================

<img src="{{ site.url }}/res/architecture.png" width="100%"/>

<br>

---

<br>

The Architecture
================

* Neurons: ReLUs train 6x faster than saturating neurons with gradient descent
* Hardware: enough training examples for enough network for two GPUs
* Local response normalization, see next slide
* Overlapping pooling, 3x3 pools on a 2x2 grid

<br>

---

<br>

Local Response Normalization
============================

<img src="{{ site.url }}/res/local_normalization.png" width="50%" style="float: right;"/>

* \\( a_{x,y}^i \\) activation from kernel map \\(i\\) at pixel \\((x, y)\\)
* \\( b_{x,y}^i \\) normalized activation
* Hyperparameters:
  * \\( k = 2 \\)
  * \\( n = 5 \\)
  * \\( \alpha = 10^{-4} \\)
  * \\( \beta = 0.75 \\)

<br>

---

<br>

Data augmentation
=================

* Translations and horizontal reflections
* Change the color and intensity of illumination

<br>

---

<br>

Dropout
=======

* Used in first two fully-connected layers
* Doubles iterations to convergence
* "Without dropout, our network exhibits substantial overfitting."

<br>

---

<br>

Training
========

<img src="{{ site.url }}/res/weight_update.png" width="50%" style="float: right;"/>

* stochastic gradient descent
  * batch size, 128
  * momentum, 0.9
  * weight decay, 0.0005
* weights initialized with normal distribution, \\( \mu=0, \sigma=0.01 \\)
* some biases initialized to 1, to provide ReLUs positive input

Altogether, 5-6 days on two NVIDIA GTX 580 3GB GPUs.

<br>

---

<br>

Results
=======

ILSVRC 2010 data:

| Model         | Top-1 | Top-5 |
| ------------- | ----- | ----- |
| Sparse coding | 47.1% | 28.2% |
| SIFT + FVs    | 45.7% | 25.7% |
| CNN           | 37.5% | 17.0% |

ILSVRC 2012:

| Model      | Top-1 (val) | Top-5 (val) | Top-5 (test) |
| ---------- | ----------- | ----------- | ------------ |
| SIFT + FVs | -           | -           | 26.2%        |
| 1 CNN      | 40.7%       | 18.2%       | -            |
| 5 CNNs     | 38.1%       | 16.4%       | 16.4%        |
| 1 CNN*     | 39.0%       | 16.6%       | -            |
| 7 CNNs*    | 36.7%       | 15.4%       | 15.3%        |

<br>

---

<br>

Qualitative Evaluations (pictures :-D)
======================================

<img src="{{ site.url }}/res/results_pics.png" width="100%"/>


<br>

---

<br>

ReNet
=====

* DNN for object recognition using a recurrent architecture
* Replace convolution-and-pooling with with RNNs that sweep across image
* Comparable performance to CNNs on MNIST, CIFAR-10, SVHN

<br>

---

<br>

One layer of ReNet
==================

<img src="{{ site.url }}/res/renet_layer.png" width="40%" style="float:right;"/>

* Split image into patches (2x2)
* Vertical sweeps take input from patches
* Horizontal sweeps take input from vertical sweeps
* Two outputs for each (patch, recurrent unit)
* Output includes context from entire image

<br>

---

<br>

NOT ReNet
=========

The authors are careful to draw a distinction with multidimensional RNNs:

<img src="{{ site.url }}/res/mdrnn.png" width="45%"/>

From [Graves and Schmidhuber, 2009](http://papers.nips.cc/paper/3449-offline-handwriting-recognition-with-multidimensional-recurrent-neural-networks).

<br>

---

<br>

ReNet vs. LeNet
===============

| LeNet | ReNet |
| --- | --- |
| Local information only | Information propagated laterally |
| Max pooling for translational invariance | Learned lateral connections |
| Max cannot be reversed, cannot be a decoder | End-to-end smooth and differentiable |
| Each layer embarrassingly parallel | Many serial calculations in each layer |

<br>

---

<br>

Experiments: datasets
=====================

* MNIST: 70k digits, 28x28, 256 grayscale
* CIFAR-10: 60k images from 10 categories, 32x32, three color channels
* Street View House Numbers: ~620k images, 32x32, three color channels,

<br>

---

<br>

Experiments: data augmentation
==============================

* Flipped horizontally or vertically
* Shifted 2px left or right
* Shifted 2px up or down

Padded with zeros.

<br>

---

<br>

Experiments: architecture
=========================

<img src="{{ site.url }}/res/renet_architecture.png" width="100%"/>

<br>

---

<br>

Experiments: training
=====================

* Adaptive learning rate algorithm, Adam
* Dropout after every layer
* Masked each input with probability 0.2

<br>

---

<br>

Results
=======

<img src="{{ site.url }}/res/renet_results.png" width="100%"/>

